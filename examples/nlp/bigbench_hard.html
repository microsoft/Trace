
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>BigBench-Hard &#8212; Trace</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
    <link rel="stylesheet" type="text/css" href="../../_static/compatibility.css?v=9fb3345b" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script data-domain="microsoft.github.io/trace" defer="defer" src="https://plausible.io/js/script.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'examples/nlp/bigbench_hard';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Meta-World" href="../robotics/metaworld.html" />
    <link rel="prev" title="Multi-Agent: Negotiation Arena" href="../game/negotiation_arena.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/trace_logo.png" class="logo__image only-light" alt="Trace - Home"/>
    <script>document.write(`<img src="../../_static/trace_logo.png" class="logo__image only-dark" alt="Trace - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    üéØ Trace
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">üí°Quick Start</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../quickstart/installation.html">üåê  Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quickstart/quick_start.html">‚ö°Ô∏è First: 5-Minute Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quickstart/quick_start_2.html">üöÄ Next: Adaptive Agent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quickstart/virtualhome.html">ü§Ø Finally: Emergent Behaviors</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">üìöTutorials</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/basic_tutorial.html">Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/optimization_tutorial.html">Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/error_handling_tutorial.html">Error Handling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/custom_optimizers.html">Building Custom Optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/minibatch.html">Batch Optimization</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Agent Examples</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../game/battleship.html">Single Agent: Battleship</a></li>


<li class="toctree-l1"><a class="reference internal" href="../game/negotiation_arena.html">Multi-Agent: Negotiation Arena</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">NLP Examples</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">BigBench-Hard</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Robotics Examples</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../robotics/metaworld.html">Meta-World</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../faq/faq.html">FAQ</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">üìñ API Reference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../api/opto.html">opto</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../api/opto.optimizers.html">opto.optimizers</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../api/opto.optimizers.buffers.html">opto.optimizers.buffers</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.optimizers.buffers.FIFOBuffer.html">opto.optimizers.buffers.FIFOBuffer</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../api/opto.optimizers.opro.html">opto.optimizers.opro</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.optimizers.opro.OPRO.html">opto.optimizers.opro.OPRO</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../api/opto.optimizers.optimizer.html">opto.optimizers.optimizer</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.optimizers.optimizer.AbstractOptimizer.html">opto.optimizers.optimizer.AbstractOptimizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.optimizers.optimizer.Optimizer.html">opto.optimizers.optimizer.Optimizer</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../api/opto.optimizers.optoprime.html">opto.optimizers.optoprime</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.optimizers.optoprime.get_fun_name.html">opto.optimizers.optoprime.get_fun_name</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.optimizers.optoprime.node_to_function_feedback.html">opto.optimizers.optoprime.node_to_function_feedback</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.optimizers.optoprime.repr_function_call.html">opto.optimizers.optoprime.repr_function_call</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.optimizers.optoprime.FunctionFeedback.html">opto.optimizers.optoprime.FunctionFeedback</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.optimizers.optoprime.OptoPrime.html">opto.optimizers.optoprime.OptoPrime</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.optimizers.optoprime.ProblemInstance.html">opto.optimizers.optoprime.ProblemInstance</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../api/opto.optimizers.optoprimemulti.html">opto.optimizers.optoprimemulti</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.optimizers.optoprimemulti.OptoPrimeMulti.html">opto.optimizers.optoprimemulti.OptoPrimeMulti</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../api/opto.optimizers.textgrad.html">opto.optimizers.textgrad</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.optimizers.textgrad.GRADIENT_MULTIPART_TEMPLATE.html">opto.optimizers.textgrad.GRADIENT_MULTIPART_TEMPLATE</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.optimizers.textgrad.GRADIENT_OF_RESULTS_INSTRUCTION.html">opto.optimizers.textgrad.GRADIENT_OF_RESULTS_INSTRUCTION</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.optimizers.textgrad.construct_reduce_prompt.html">opto.optimizers.textgrad.construct_reduce_prompt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.optimizers.textgrad.construct_tgd_prompt.html">opto.optimizers.textgrad.construct_tgd_prompt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.optimizers.textgrad.get_short_value.html">opto.optimizers.textgrad.get_short_value</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.optimizers.textgrad.rm_node_attrs.html">opto.optimizers.textgrad.rm_node_attrs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.optimizers.textgrad.GradientInfo.html">opto.optimizers.textgrad.GradientInfo</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.optimizers.textgrad.TextGrad.html">opto.optimizers.textgrad.TextGrad</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../api/opto.optimizers.utils.html">opto.optimizers.utils</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.optimizers.utils.print_color.html">opto.optimizers.utils.print_color</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../api/opto.trace.html">opto.trace</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../api/opto.trace.stop_tracing.html">opto.trace.stop_tracing</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../api/opto.trace.broadcast.html">opto.trace.broadcast</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.broadcast.apply_op.html">opto.trace.broadcast.apply_op</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.broadcast.recursive_conversion.html">opto.trace.broadcast.recursive_conversion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api/opto.trace.bundle.html">opto.trace.bundle</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../api/opto.trace.containers.html">opto.trace.containers</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.containers.trainable_method.html">opto.trace.containers.trainable_method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.containers.Map.html">opto.trace.containers.Map</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.containers.NodeContainer.html">opto.trace.containers.NodeContainer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.containers.ParameterContainer.html">opto.trace.containers.ParameterContainer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.containers.Seq.html">opto.trace.containers.Seq</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../api/opto.trace.errors.html">opto.trace.errors</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.errors.ExecutionError.html">opto.trace.errors.ExecutionError</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.errors.TraceMissingInputsError.html">opto.trace.errors.TraceMissingInputsError</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../api/opto.trace.iterators.html">opto.trace.iterators</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.iterators.iterate.html">opto.trace.iterators.iterate</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.iterators.DictIterable.html">opto.trace.iterators.DictIterable</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.iterators.SeqIterable.html">opto.trace.iterators.SeqIterable</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../api/opto.trace.modules.html">opto.trace.modules</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.modules.model.html">opto.trace.modules.model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.modules.Module.html">opto.trace.modules.Module</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../api/opto.trace.nodes.html">opto.trace.nodes</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.nodes.get_op_name.html">opto.trace.nodes.get_op_name</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.nodes.node-function.html">opto.trace.nodes.node</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.nodes.AbstractNode.html">opto.trace.nodes.AbstractNode</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.nodes.ExceptionNode.html">opto.trace.nodes.ExceptionNode</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.nodes.Graph.html">opto.trace.nodes.Graph</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.nodes.MessageNode.html">opto.trace.nodes.MessageNode</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.nodes.Node.html">opto.trace.nodes.Node</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.nodes.NodeVizStyleGuide.html">opto.trace.nodes.NodeVizStyleGuide</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.nodes.NodeVizStyleGuideColorful.html">opto.trace.nodes.NodeVizStyleGuideColorful</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.nodes.ParameterNode.html">opto.trace.nodes.ParameterNode</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../api/opto.trace.operators.html">opto.trace.operators</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.operators.identity.html">opto.trace.operators.identity</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../api/opto.trace.propagators.html">opto.trace.propagators</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.propagators.graph_propagator.html">opto.trace.propagators.graph_propagator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.propagators.propagators.html">opto.trace.propagators.propagators</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../api/opto.trace.utils.html">opto.trace.utils</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-19"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.utils.contain.html">opto.trace.utils.contain</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.utils.escape_json_nested_quotes.html">opto.trace.utils.escape_json_nested_quotes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.utils.for_all_methods.html">opto.trace.utils.for_all_methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.utils.parse_eqs_to_dict.html">opto.trace.utils.parse_eqs_to_dict</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.utils.remove_non_ascii.html">opto.trace.utils.remove_non_ascii</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.utils.render_opt_step.html">opto.trace.utils.render_opt_step</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.utils.sum_feedback.html">opto.trace.utils.sum_feedback</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.trace.utils.test_json_quote_escaper.html">opto.trace.utils.test_json_quote_escaper</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../api/opto.utils.html">opto.utils</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-20"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../api/opto.utils.llm.html">opto.utils.llm</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-21"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.utils.llm.auto_construct_oai_config_list_from_env.html">opto.utils.llm.auto_construct_oai_config_list_from_env</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.utils.llm.AbstractModel.html">opto.utils.llm.AbstractModel</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.utils.llm.AutoGenLLM.html">opto.utils.llm.AutoGenLLM</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.utils.llm.CustomLLM.html">opto.utils.llm.CustomLLM</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.utils.llm.LLM.html">opto.utils.llm.LLM</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/opto.utils.llm.LiteLLM.html">opto.utils.llm.LiteLLM</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../api/opto.version.html">opto.version</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/microsoft/Trace/blob/website/docs/examples/nlp/bigbench_hard.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>



<a href="https://github.com/microsoft/Trace" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/examples/nlp/bigbench_hard.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>BigBench-Hard</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setup">Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#define-the-evaluation-function">Define the Evaluation Function</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#helper-function">Helper Function</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#define-a-traced-class">Define a Traced Class</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#define-the-optimizer">Define the optimizer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#putting-it-all-together">Putting it all together</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="bigbench-hard">
<h1>BigBench-Hard<a class="headerlink" href="#bigbench-hard" title="Link to this heading">#</a></h1>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Link to this heading">#</a></h2>
<p>In this notebook, we will demonstrate how to use the <code class="docutils literal notranslate"><span class="pre">trace</span></code> package to optimize prompts and code for natural language processing tasks using the BigBench-Hard benchmark. SotA approaches on this benchmark only optimize prompts, while relying on hand-written code to extract answers from LLM responses. By leveraging the LLM-based optimizers provided in <code class="docutils literal notranslate"><span class="pre">trace</span></code>, we aim to enhance the performance of a workflow calling LLMs and post-processing their responses in generating accurate and relevant answers.</p>
</section>
<section id="setup">
<h2>Setup<a class="headerlink" href="#setup" title="Link to this heading">#</a></h2>
<p>First, we‚Äôll import the necessary packages and set up our environment. We will use a copy of the BigBench-Hard benchmark hosted on <a class="reference external" href="https://huggingface.co/datasets/maveriq/bigbenchhard">HuggingFace</a>. To use HuggingFace datasets, ensure that you have the <code class="docutils literal notranslate"><span class="pre">datasets</span></code> package installed:</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To replicate our experiment in the paper, run the script here:
<a class="github reference external" href="https://github.com/microsoft/Trace/blob/main/examples/bbh/run_prompt_bigbench_trace.py">microsoft/Trace</a></p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">pip</span> install datasets
<span class="o">%</span><span class="k">pip</span> install trace-opt
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import necessary libraries</span>
<span class="kn">import</span> <span class="nn">autogen</span>
<span class="kn">from</span> <span class="nn">opto.trace.nodes</span> <span class="kn">import</span> <span class="n">node</span><span class="p">,</span> <span class="n">GRAPH</span><span class="p">,</span> <span class="n">ParameterNode</span>
<span class="kn">from</span> <span class="nn">opto.optimizers</span> <span class="kn">import</span> <span class="n">OptoPrime</span>
<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span> <span class="nn">textwrap</span> <span class="kn">import</span> <span class="n">dedent</span>
<span class="kn">from</span> <span class="nn">opto.trace.bundle</span> <span class="kn">import</span> <span class="n">bundle</span>
<span class="kn">from</span> <span class="nn">opto.trace.modules</span> <span class="kn">import</span> <span class="n">model</span>
<span class="kn">from</span> <span class="nn">opto.trace.errors</span> <span class="kn">import</span> <span class="n">ExecutionError</span>
<span class="kn">from</span> <span class="nn">opto.trace.nodes</span> <span class="kn">import</span> <span class="n">ExceptionNode</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>
<span class="kn">import</span> <span class="nn">re</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/aswaminathan/miniconda3/envs/trace/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span>

<span class="c1"># Function to save the environment variable and API key</span>
<span class="k">def</span> <span class="nf">save_env_variable</span><span class="p">(</span><span class="n">env_name</span><span class="p">,</span> <span class="n">api_key</span><span class="p">):</span>
    <span class="c1"># Validate inputs</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">env_name</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;‚ö†Ô∏è Environment variable name cannot be empty.&quot;</span><span class="p">)</span>
        <span class="k">return</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">api_key</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;‚ö†Ô∏è API key cannot be empty.&quot;</span><span class="p">)</span>
        <span class="k">return</span>
    
    <span class="c1"># Store the API key as an environment variable</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="n">env_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">api_key</span>
    <span class="nb">globals</span><span class="p">()[</span><span class="n">env_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">api_key</span>  <span class="c1"># Set it as a global variable</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;‚úÖ API key has been set for environment variable: </span><span class="si">{</span><span class="n">env_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Create the input widgets</span>
<span class="n">env_name_input</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Text</span><span class="p">(</span>
    <span class="n">value</span><span class="o">=</span><span class="s2">&quot;OPENAI_API_KEY&quot;</span><span class="p">,</span>  <span class="c1"># Default value</span>
    <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Env Name:&quot;</span><span class="p">,</span>
    <span class="n">placeholder</span><span class="o">=</span><span class="s2">&quot;Enter env variable name (e.g., MY_API_KEY)&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">api_key_input</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Password</span><span class="p">(</span>
    <span class="n">description</span><span class="o">=</span><span class="s2">&quot;API Key:&quot;</span><span class="p">,</span>
    <span class="n">placeholder</span><span class="o">=</span><span class="s2">&quot;Enter your API key&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Create the button to submit the inputs</span>
<span class="n">submit_button</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Button</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">&quot;Set API Key&quot;</span><span class="p">)</span>

<span class="c1"># Display the widgets</span>
<span class="n">display</span><span class="p">(</span><span class="n">env_name_input</span><span class="p">,</span> <span class="n">api_key_input</span><span class="p">,</span> <span class="n">submit_button</span><span class="p">)</span>

<span class="c1"># Callback function for the button click</span>
<span class="k">def</span> <span class="nf">on_button_click</span><span class="p">(</span><span class="n">b</span><span class="p">):</span>
    <span class="n">env_name</span> <span class="o">=</span> <span class="n">env_name_input</span><span class="o">.</span><span class="n">value</span>
    <span class="n">api_key</span> <span class="o">=</span> <span class="n">api_key_input</span><span class="o">.</span><span class="n">value</span>
    <span class="n">save_env_variable</span><span class="p">(</span><span class="n">env_name</span><span class="p">,</span> <span class="n">api_key</span><span class="p">)</span>

<span class="c1"># Attach the callback to the button</span>
<span class="n">submit_button</span><span class="o">.</span><span class="n">on_click</span><span class="p">(</span><span class="n">on_button_click</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="define-the-evaluation-function">
<h2>Define the Evaluation Function<a class="headerlink" href="#define-the-evaluation-function" title="Link to this heading">#</a></h2>
<p>Next, we‚Äôll define the utility function for evaluating answers obtained by prompting an LLM.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">eval_metric</span><span class="p">(</span><span class="n">true</span><span class="p">,</span> <span class="n">prediction</span><span class="p">):</span>
    <span class="n">matches</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;\([A-Z]\)&quot;</span><span class="p">,</span> <span class="n">true</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">matches</span><span class="p">:</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">prediction</span>
        <span class="n">matches</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;\([A-Z]\)&quot;</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
        <span class="n">parsed_answer</span> <span class="o">=</span> <span class="n">matches</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="n">matches</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span>
        <span class="k">return</span> <span class="n">parsed_answer</span> <span class="o">==</span> <span class="n">true</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">prediction</span> <span class="o">==</span> <span class="n">true</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="helper-function">
<h2>Helper Function<a class="headerlink" href="#helper-function" title="Link to this heading">#</a></h2>
<p>We‚Äôll create a helper class called <code class="docutils literal notranslate"><span class="pre">LLMCallable</span></code> to interact with the LLM API.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LLMCallable</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config_list</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_tokens</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">config_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">config_list</span> <span class="o">=</span> <span class="n">autogen</span><span class="o">.</span><span class="n">config_list_from_json</span><span class="p">(</span><span class="s2">&quot;OAI_CONFIG_LIST&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">llm</span> <span class="o">=</span> <span class="n">autogen</span><span class="o">.</span><span class="n">OpenAIWrapper</span><span class="p">(</span><span class="n">config_list</span><span class="o">=</span><span class="n">config_list</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_tokens</span> <span class="o">=</span> <span class="n">max_tokens</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>

    <span class="nd">@bundle</span><span class="p">(</span><span class="n">catch_execution_error</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">call_llm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">user_prompt</span><span class="p">):</span>
        <span class="n">system_prompt</span> <span class="o">=</span> <span class="s2">&quot;You are a helpful assistant.</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">messages</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">system_prompt</span><span class="p">},</span> <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">user_prompt</span><span class="p">}]</span>
        <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">llm</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span> <span class="n">max_tokens</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_tokens</span><span class="p">)</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;LLM response:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">response</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">response</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="define-a-traced-class">
<h2>Define a Traced Class<a class="headerlink" href="#define-a-traced-class" title="Link to this heading">#</a></h2>
<p>We will define a Predict class to generate predictions using LLM. Note that we use a module provided by <code class="docutils literal notranslate"><span class="pre">trace</span></code> called <code class="docutils literal notranslate"><span class="pre">Model</span></code> which can wrap a python class to enable tracing.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@model</span>
<span class="k">class</span> <span class="nc">Predict</span><span class="p">(</span><span class="n">LLMCallable</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">demos</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span> <span class="n">prompt_template</span> <span class="o">=</span> <span class="n">dedent</span><span class="p">(</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Given the fields `question`, produce the fields `answer`.</span>

<span class="sd">        ---</span>

<span class="sd">        Follow the following format.</span>

<span class="sd">        Question: </span>
<span class="sd">        Answer: </span>

<span class="sd">        ---</span>
<span class="sd">        Question: {}</span>
<span class="sd">        Answer:</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span> <span class="o">=</span> <span class="n">ParameterNode</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                             <span class="n">description</span><span class="o">=</span><span class="s2">&quot;This is the Prompt Template to the LLM. &quot;</span> <span class="o">+</span> \
                                                         <span class="s2">&quot;Need to include information about what the format of answers LLM should output. &quot;</span> <span class="o">+</span> \
                                                         <span class="s2">&quot;They can be (A)/(B), a number like 8, or a string, or Yes/No.&quot;</span><span class="p">)</span>

    <span class="nd">@bundle</span><span class="p">(</span><span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">catch_execution_error</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">allow_external_dependencies</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">extract_answer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt_template</span><span class="p">,</span> <span class="n">question</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">answer</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;Answer:&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">answer</span>

    <span class="nd">@bundle</span><span class="p">(</span><span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">catch_execution_error</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">allow_external_dependencies</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">create_prompt</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt_template</span><span class="p">,</span> <span class="n">question</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">prompt_template</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">question</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">question</span><span class="p">):</span>
        <span class="n">user_prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_prompt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span><span class="p">,</span> <span class="n">question</span><span class="p">)</span>
        <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">call_llm</span><span class="p">(</span><span class="n">user_prompt</span><span class="p">)</span>
        <span class="n">answer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extract_answer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span><span class="p">,</span> <span class="n">question</span><span class="p">,</span> <span class="n">response</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">answer</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="define-the-optimizer">
<h2>Define the optimizer<a class="headerlink" href="#define-the-optimizer" title="Link to this heading">#</a></h2>
<p>Note that the <code class="docutils literal notranslate"><span class="pre">prompt_template</span></code> is a <code class="docutils literal notranslate"><span class="pre">ParameterNode</span></code> as well as the <code class="docutils literal notranslate"><span class="pre">extract_answer</span></code> is a trainable function. <code class="docutils literal notranslate"><span class="pre">trace</span></code> handles the optimization of heterogenous parameters seamlessly.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">dp</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">examples</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="n">example</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">response</span> <span class="o">=</span> <span class="n">dp</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="s1">&#39;question&#39;</span><span class="p">])</span>
            <span class="n">correctness</span> <span class="o">=</span> <span class="n">eval_metric</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="s1">&#39;answer&#39;</span><span class="p">],</span> <span class="n">response</span><span class="p">)</span>
            <span class="n">feedback</span> <span class="o">=</span> <span class="s2">&quot;The answer is correct! No need to change anything.&quot;</span> <span class="k">if</span> <span class="n">correctness</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;The answer is wrong. We expect the output of your answer to be </span><span class="se">\&quot;</span><span class="si">{</span><span class="n">example</span><span class="p">[</span><span class="s1">&#39;answer&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\&quot;</span><span class="s2">. Please modify the prompt and relevant parts of the program to help LLM produce the right answer.&quot;</span>
        <span class="k">except</span> <span class="n">ExecutionError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">response</span> <span class="o">=</span> <span class="n">e</span><span class="o">.</span><span class="n">exception_node</span>
            <span class="n">feedback</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">data</span>
            <span class="n">correctness</span> <span class="o">=</span> <span class="kc">False</span>
            
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Question:&quot;</span><span class="p">,</span> <span class="n">example</span><span class="p">[</span><span class="s2">&quot;question&quot;</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Expected answer:&quot;</span><span class="p">,</span> <span class="n">example</span><span class="p">[</span><span class="s2">&quot;answer&quot;</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Answer:&quot;</span><span class="p">,</span> <span class="n">response</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">correctness</span><span class="p">:</span>
            <span class="k">continue</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_feedback</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">response</span><span class="p">,</span> <span class="n">feedback</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output: </span><span class="si">{</span><span class="n">response</span><span class="si">}</span><span class="s2">, Feedback: </span><span class="si">{</span><span class="n">feedback</span><span class="si">}</span><span class="s2">, Variables:&quot;</span><span class="p">)</span>  <span class="c1"># Logging</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">parameters</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="putting-it-all-together">
<h2>Putting it all together<a class="headerlink" href="#putting-it-all-together" title="Link to this heading">#</a></h2>
<p>Finally, we use the optimizer to find better prompts using a small training set as follows.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">task</span> <span class="o">=</span> <span class="s2">&quot;sports_understanding&quot;</span>
<span class="n">train_set</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;maveriq/bigbenchhard&quot;</span><span class="p">,</span> <span class="n">task</span><span class="p">)[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span>
<span class="n">examples</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="n">r</span><span class="p">[</span><span class="s2">&quot;input&quot;</span><span class="p">],</span> <span class="s2">&quot;answer&quot;</span><span class="p">:</span> <span class="n">r</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]}</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">train_set</span><span class="p">]</span>

<span class="n">dp</span> <span class="o">=</span> <span class="n">Predict</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">OptoPrime</span><span class="p">(</span><span class="n">dp</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
                                    <span class="n">config_list</span><span class="o">=</span><span class="n">autogen</span><span class="o">.</span><span class="n">config_list_from_json</span><span class="p">(</span><span class="s2">&quot;OAI_CONFIG_LIST&quot;</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training on a few examples:&quot;</span><span class="p">)</span>
<span class="n">train</span><span class="p">(</span><span class="n">dp</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">examples</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>

<span class="n">test_accuracy</span> <span class="o">=</span> <span class="p">[]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Testing on new examples:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">[</span><span class="mi">5</span><span class="p">:</span><span class="mi">10</span><span class="p">]:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">dp</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="s2">&quot;question&quot;</span><span class="p">])</span>
        <span class="n">correctness</span> <span class="o">=</span> <span class="n">eval_metric</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="s2">&quot;answer&quot;</span><span class="p">],</span> <span class="n">response</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">ExecutionError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">correctness</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">test_accuracy</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">correctness</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy: &quot;</span><span class="p">,</span> <span class="nb">sum</span><span class="p">(</span><span class="n">test_accuracy</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_accuracy</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training on a few examples:
Question: Is the following sentence plausible? &quot;Elias Lindholm beat the buzzer.&quot;
Expected answer: no
Answer: MessageNode: (eval:1, dtype=&lt;class &#39;str&#39;&gt;, data=Yes, the sentence &quot;Elias Lindholm beat the buzzer&quot; is plausible. It is commonly used in sports contexts to describe a scenario where a player, such as Elias Lindholm in ice hockey, scores just before the time runs out in a period or game.)
Output: MessageNode: (eval:1, dtype=&lt;class &#39;str&#39;&gt;, data=Yes, the sentence &quot;Elias Lindholm beat the buzzer&quot; is plausible. It is commonly used in sports contexts to describe a scenario where a player, such as Elias Lindholm in ice hockey, scores just before the time runs out in a period or game.), Feedback: The answer is wrong. We expect the output of your answer to be &quot;no&quot;. Please modify the prompt and relevant parts of the program to help LLM produce the right answer., Variables:
__code:1 def create_prompt(self, prompt_template, question):
        return prompt_template.format(question)
__code:0 def extract_answer(self, prompt_template, question, response):
        answer = response.split(&quot;Answer:&quot;)[1].strip()
        return answer
str:0 
Given the fields `question`, produce the fields `answer`.

---

Follow the following format.

Question: 
Answer: 

---
Question: {}
Answer:

Prompt
 
You&#39;re tasked to solve a coding/algorithm problem. You will see the instruction, the code, the documentation of each function used in the code, and the feedback about the execution result.

Specifically, a problem will be composed of the following parts:
- #Instruction: the instruction which describes the things you need to do or the question you should answer.
- #Code: the code defined in the problem.
- #Documentation: the documentation of each function used in #Code. The explanation might be incomplete and just contain high-level description. You can use the values in #Others to help infer how those functions work.
- #Variables: the input variables that you can change.
- #Constraints: the constraints or descriptions of the variables in #Variables.
- #Inputs: the values of other inputs to the code, which are not changeable.
- #Others: the intermediate values created through the code execution.
- #Outputs: the result of the code output.
- #Feedback: the feedback about the code&#39;s execution result.

In #Variables, #Inputs, #Outputs, and #Others, the format is:

&lt;data_type&gt; &lt;variable_name&gt; = &lt;value&gt;

If &lt;type&gt; is (code), it means &lt;value&gt; is the source code of a python code, which may include docstring and definitions.

Output_format: Your output should be in the following json format, satisfying the json syntax:

{{
&quot;reasoning&quot;: &lt;Your reasoning&gt;,
&quot;answer&quot;: &lt;Your answer&gt;,
&quot;suggestion&quot;: {{
    &lt;variable_1&gt;: &lt;suggested_value_1&gt;,
    &lt;variable_2&gt;: &lt;suggested_value_2&gt;,
}}
}}

In &quot;reasoning&quot;, explain the problem: 1. what the #Instruction means 2. what the #Feedback on #Output means to #Variables considering how #Variables are used in #Code and other values in #Documentation, #Inputs, #Others. 3. Reasoning about the suggested changes in #Variables (if needed) and the expected result.

If #Instruction asks for an answer, write it down in &quot;answer&quot;.

If you need to suggest a change in the values of #Variables, write down the suggested values in &quot;suggestion&quot;. Remember you can change only the values in #Variables, not others. When &lt;type&gt; of a variable is (code), you should write the new definition in the format of python code without syntax errors, and you should not change the function name or the function signature.

If no changes or answer are needed, just output TERMINATE.

Now you see problem instance:

================================

#Instruction
You need to change the &lt;value&gt; of the variables in #Variables to improve the output in accordance to #Feedback.

#Code
eval0 = eval(self=self0, prompt_template=str0, question=question0, __code=__code1)
LLMCallable.call_llm0 = LLMCallable.call_llm(self=self1, user_prompt=eval0)
eval1 = eval(self=self2, prompt_template=str0, question=question1, response=LLMCallable.call_llm0, __code=__code0)

#Documentation
[eval] This operator eval(__code, *args, **kwargs) evaluates the code block, where __code is the code (str) and *args and **kwargs are the arguments of the function. The output is the result of the evaluation, i.e., __code(*args, **kwargs).
[LLMCallable.call_llm] .

#Variables
(str) str0=
Given the fields `question`, produce the fields `answer`.

---

Follow the following format.

Question: 
Answer: 

---
Question: {}
Answer:

(code) __code1:def create_prompt(self, prompt_template, question):
        return prompt_template.format(question)
(code) __code0:def extract_answer(self, prompt_template, question, response):
        answer = response.split(&quot;Answer:&quot;)[1].strip()
        return answer

#Constraints
(code) __code1: The code should start with:
def create_prompt(self, prompt_template, question):
(code) __code0: The code should start with:
def extract_answer(self, prompt_template, question, response):

#Inputs
(ModelWrapper) self2=&lt;opto.trace.modules.model.&lt;locals&gt;.ModelWrapper object at 0x7f4bd428a410&gt;
(str) question1=Is the following sentence plausible? &quot;Elias Lindholm beat the buzzer.&quot;
(ModelWrapper) self1=&lt;opto.trace.modules.model.&lt;locals&gt;.ModelWrapper object at 0x7f4bd428a410&gt;
(ModelWrapper) self0=&lt;opto.trace.modules.model.&lt;locals&gt;.ModelWrapper object at 0x7f4bd428a410&gt;
(str) question0=Is the following sentence plausible? &quot;Elias Lindholm beat the buzzer.&quot;

#Others
(str) eval0=
Given the fields `question`, produce the fields `answer`.

---

Follow the following format.

Question: 
Answer: 

---
Question: Is the following sentence plausible? &quot;Elias Lindholm beat the buzzer.&quot;
Answer:

(str) LLMCallable.call_llm0=Question: Is the following sentence plausible? &quot;Elias Lindholm beat the buzzer.&quot;
Answer: Yes, the sentence &quot;Elias Lindholm beat the buzzer&quot; is plausible. It is commonly used in sports contexts to describe a scenario where a player, such as Elias Lindholm in ice hockey, scores just before the time runs out in a period or game.

#Outputs
(str) eval1=Yes, the sentence &quot;Elias Lindholm beat the buzzer&quot; is plausible. It is commonly used in sports contexts to describe a scenario where a player, such as Elias Lindholm in ice hockey, scores just before the time runs out in a period or game.

#Feedback
The answer is wrong. We expect the output of your answer to be &quot;no&quot;. Please modify the prompt and relevant parts of the program to help LLM produce the right answer.

================================


Your response:

LLM response:
 {
  &quot;reasoning&quot;: &quot;The objective is to modify the prompt template (str0) such that the Language Model (LLM) produces an answer that aligns with the expected answer &#39;no&#39; as opposed to &#39;yes&#39;. The function &#39;create_prompt&#39; as defined by &#39;__code1&#39;, uses the prompt template (str0) to format a question. The prompt template instructs how the question should be posed to the LLM. Currently, the prompt template is generic and does not guide the LLM towards evaluating the plausibility of the statement correctly. Since the feedback demands a specific answer (&#39;no&#39;), the prompt template itself should be tailored to facilitate evaluating the plausibility specifically, possibly by providing a context or criteria under which the statement might be deemed implausible. The function &#39;extract_answer&#39; as defined by &#39;__code0&#39; correctly identifies the answer segment from the LLM&#39;s output, and hence does not require changes.&quot;,
  &quot;suggestion&quot;: {
    &quot;str0&quot;: &quot;Given the grammatical fields `question`, produce the fields `answer`.\n\n---\n\nPlease analyze the grammatical plausibility of the question provided:\n\nQuestion: {}\nAnswer:&quot;
  }
}
Question: Is the following sentence plausible? &quot;John Carlson scored in the third period.&quot;
Expected answer: yes
Answer: MessageNode: (exception_eval:0, dtype=&lt;class &#39;str&#39;&gt;, data=(IndexError) list index out of range)
Output: MessageNode: (exception_eval:0, dtype=&lt;class &#39;str&#39;&gt;, data=(IndexError) list index out of range), Feedback: (IndexError) list index out of range, Variables:
__code:1 def create_prompt(self, prompt_template, question):
        return prompt_template.format(question)
__code:0 def extract_answer(self, prompt_template, question, response):
        answer = response.split(&quot;Answer:&quot;)[1].strip()
        return answer
str:0 Given the grammatical fields `question`, produce the fields `answer`.

---

Please analyze the grammatical plausibility of the question provided:

Question: {}
Answer:
Prompt
 
You&#39;re tasked to solve a coding/algorithm problem. You will see the instruction, the code, the documentation of each function used in the code, and the feedback about the execution result.

Specifically, a problem will be composed of the following parts:
- #Instruction: the instruction which describes the things you need to do or the question you should answer.
- #Code: the code defined in the problem.
- #Documentation: the documentation of each function used in #Code. The explanation might be incomplete and just contain high-level description. You can use the values in #Others to help infer how those functions work.
- #Variables: the input variables that you can change.
- #Constraints: the constraints or descriptions of the variables in #Variables.
- #Inputs: the values of other inputs to the code, which are not changeable.
- #Others: the intermediate values created through the code execution.
- #Outputs: the result of the code output.
- #Feedback: the feedback about the code&#39;s execution result.

In #Variables, #Inputs, #Outputs, and #Others, the format is:

&lt;data_type&gt; &lt;variable_name&gt; = &lt;value&gt;

If &lt;type&gt; is (code), it means &lt;value&gt; is the source code of a python code, which may include docstring and definitions.

Output_format: Your output should be in the following json format, satisfying the json syntax:

{{
&quot;reasoning&quot;: &lt;Your reasoning&gt;,
&quot;answer&quot;: &lt;Your answer&gt;,
&quot;suggestion&quot;: {{
    &lt;variable_1&gt;: &lt;suggested_value_1&gt;,
    &lt;variable_2&gt;: &lt;suggested_value_2&gt;,
}}
}}

In &quot;reasoning&quot;, explain the problem: 1. what the #Instruction means 2. what the #Feedback on #Output means to #Variables considering how #Variables are used in #Code and other values in #Documentation, #Inputs, #Others. 3. Reasoning about the suggested changes in #Variables (if needed) and the expected result.

If #Instruction asks for an answer, write it down in &quot;answer&quot;.

If you need to suggest a change in the values of #Variables, write down the suggested values in &quot;suggestion&quot;. Remember you can change only the values in #Variables, not others. When &lt;type&gt; of a variable is (code), you should write the new definition in the format of python code without syntax errors, and you should not change the function name or the function signature.

If no changes or answer are needed, just output TERMINATE.

Now you see problem instance:

================================

#Instruction
You need to change the &lt;value&gt; of the variables in #Variables to improve the output in accordance to #Feedback.

#Code
eval2 = eval(self=self3, prompt_template=str0, question=question2, __code=__code1)
LLMCallable.call_llm1 = LLMCallable.call_llm(self=self4, user_prompt=eval2)
exception_eval0 = eval(self=self5, prompt_template=str0, question=question3, response=LLMCallable.call_llm1, __code=__code0)

#Documentation
[exception] The operator eval raises an exception.
[LLMCallable.call_llm] .

#Variables
(str) str0=Given the grammatical fields `question`, produce the fields `answer`.

---

Please analyze the grammatical plausibility of the question provided:

Question: {}
Answer:
(code) __code1:def create_prompt(self, prompt_template, question):
        return prompt_template.format(question)
(code) __code0:def extract_answer(self, prompt_template, question, response):
        answer = response.split(&quot;Answer:&quot;)[1].strip()
        return answer

#Constraints
(code) __code1: The code should start with:
def create_prompt(self, prompt_template, question):
(code) __code0: The code should start with:
def extract_answer(self, prompt_template, question, response):

#Inputs
(ModelWrapper) self5=&lt;opto.trace.modules.model.&lt;locals&gt;.ModelWrapper object at 0x7f4bd428a410&gt;
(str) question3=Is the following sentence plausible? &quot;John Carlson scored in the third period.&quot;
(ModelWrapper) self4=&lt;opto.trace.modules.model.&lt;locals&gt;.ModelWrapper object at 0x7f4bd428a410&gt;
(ModelWrapper) self3=&lt;opto.trace.modules.model.&lt;locals&gt;.ModelWrapper object at 0x7f4bd428a410&gt;
(str) question2=Is the following sentence plausible? &quot;John Carlson scored in the third period.&quot;

#Others
(str) eval2=Given the grammatical fields `question`, produce the fields `answer`.

---

Please analyze the grammatical plausibility of the question provided:

Question: Is the following sentence plausible? &quot;John Carlson scored in the third period.&quot;
Answer:
(str) LLMCallable.call_llm1=Yes, the sentence &quot;John Carlson scored in the third period.&quot; is grammatically plausible. It follows the standard subject-verb-object format and provides clear information about who did what and when. The subject is &quot;John Carlson,&quot; the verb is &quot;scored,&quot; and the phrase &quot;in the third period&quot; provides additional context about the timing of the action.

#Outputs
(str) exception_eval0=(IndexError) list index out of range

#Feedback
(IndexError) list index out of range

================================


Your response:

LLM response:
 {
    &quot;reasoning&quot;: &quot;The IndexError &#39;list index out of range&#39; usually results from trying to access an index in a list or string that doesn&#39;t exist. From the provided feedback, we see that the exception occurs when executing `exception_eval0`. Specifically, the exception arises in the `extract_answer` function defined in `__code0`. The assignment `answer = response.split(\&quot;Answer:\&quot;)[1].strip()` attempts to access the second element (index 1) after splitting `response` by the substring &#39;Answer:&#39;. If &#39;Answer:&#39; isn&#39;t found or there is no information following &#39;Answer:&#39;, the index [1] will be out of range, leading to the IndexError. In the string `LLMCallable.call_llm1`, the sentence &#39;Answer:&#39; does not immediately follow a colon but merely appears in the string, hence it doesn&#39;t split as expected. \nThe fix involves ensuring that &#39;Answer:&#39; appears correctly formatted so when split, it follows with enough content to access index [1]. Hence, the structure of `str0` should correctly prepare the `response` to include &#39;Answer:&#39; followed by the answer content.&quot;,
    &quot;suggestion&quot;: {
        &quot;str0&quot;: &quot;Given the grammatical fields `question`, produce the fields `answer`: Answer: {}&quot;
    }
}
Question: Is the following sentence plausible? &quot;Marcelo got on the end of a through ball.&quot;
Expected answer: yes
Answer: MessageNode: (eval:4, dtype=&lt;class &#39;str&#39;&gt;, data=Yes, the sentence &quot;Marcelo got on the end of a through ball&quot; is plausible. It is commonly used in sports commentary, especially in soccer (football), to describe a player receiving a pass that goes through the defense.)
Output: MessageNode: (eval:4, dtype=&lt;class &#39;str&#39;&gt;, data=Yes, the sentence &quot;Marcelo got on the end of a through ball&quot; is plausible. It is commonly used in sports commentary, especially in soccer (football), to describe a player receiving a pass that goes through the defense.), Feedback: The answer is wrong. We expect the output of your answer to be &quot;yes&quot;. Please modify the prompt and relevant parts of the program to help LLM produce the right answer., Variables:
__code:1 def create_prompt(self, prompt_template, question):
        return prompt_template.format(question)
__code:0 def extract_answer(self, prompt_template, question, response):
        answer = response.split(&quot;Answer:&quot;)[1].strip()
        return answer
str:0 Given the grammatical fields `question`, produce the fields `answer`: Answer: {}
Prompt
 
You&#39;re tasked to solve a coding/algorithm problem. You will see the instruction, the code, the documentation of each function used in the code, and the feedback about the execution result.

Specifically, a problem will be composed of the following parts:
- #Instruction: the instruction which describes the things you need to do or the question you should answer.
- #Code: the code defined in the problem.
- #Documentation: the documentation of each function used in #Code. The explanation might be incomplete and just contain high-level description. You can use the values in #Others to help infer how those functions work.
- #Variables: the input variables that you can change.
- #Constraints: the constraints or descriptions of the variables in #Variables.
- #Inputs: the values of other inputs to the code, which are not changeable.
- #Others: the intermediate values created through the code execution.
- #Outputs: the result of the code output.
- #Feedback: the feedback about the code&#39;s execution result.

In #Variables, #Inputs, #Outputs, and #Others, the format is:

&lt;data_type&gt; &lt;variable_name&gt; = &lt;value&gt;

If &lt;type&gt; is (code), it means &lt;value&gt; is the source code of a python code, which may include docstring and definitions.

Output_format: Your output should be in the following json format, satisfying the json syntax:

{{
&quot;reasoning&quot;: &lt;Your reasoning&gt;,
&quot;answer&quot;: &lt;Your answer&gt;,
&quot;suggestion&quot;: {{
    &lt;variable_1&gt;: &lt;suggested_value_1&gt;,
    &lt;variable_2&gt;: &lt;suggested_value_2&gt;,
}}
}}

In &quot;reasoning&quot;, explain the problem: 1. what the #Instruction means 2. what the #Feedback on #Output means to #Variables considering how #Variables are used in #Code and other values in #Documentation, #Inputs, #Others. 3. Reasoning about the suggested changes in #Variables (if needed) and the expected result.

If #Instruction asks for an answer, write it down in &quot;answer&quot;.

If you need to suggest a change in the values of #Variables, write down the suggested values in &quot;suggestion&quot;. Remember you can change only the values in #Variables, not others. When &lt;type&gt; of a variable is (code), you should write the new definition in the format of python code without syntax errors, and you should not change the function name or the function signature.

If no changes or answer are needed, just output TERMINATE.

Now you see problem instance:

================================

#Instruction
You need to change the &lt;value&gt; of the variables in #Variables to improve the output in accordance to #Feedback.

#Code
eval3 = eval(self=self6, prompt_template=str0, question=question4, __code=__code1)
LLMCallable.call_llm2 = LLMCallable.call_llm(self=self7, user_prompt=eval3)
eval4 = eval(self=self8, prompt_template=str0, question=question5, response=LLMCallable.call_llm2, __code=__code0)

#Documentation
[eval] This operator eval(__code, *args, **kwargs) evaluates the code block, where __code is the code (str) and *args and **kwargs are the arguments of the function. The output is the result of the evaluation, i.e., __code(*args, **kwargs).
[LLMCallable.call_llm] .

#Variables
(str) str0=Given the grammatical fields `question`, produce the fields `answer`: Answer: {}
(code) __code1:def create_prompt(self, prompt_template, question):
        return prompt_template.format(question)
(code) __code0:def extract_answer(self, prompt_template, question, response):
        answer = response.split(&quot;Answer:&quot;)[1].strip()
        return answer

#Constraints
(code) __code1: The code should start with:
def create_prompt(self, prompt_template, question):
(code) __code0: The code should start with:
def extract_answer(self, prompt_template, question, response):

#Inputs
(ModelWrapper) self8=&lt;opto.trace.modules.model.&lt;locals&gt;.ModelWrapper object at 0x7f4bd428a410&gt;
(str) question5=Is the following sentence plausible? &quot;Marcelo got on the end of a through ball.&quot;
(ModelWrapper) self7=&lt;opto.trace.modules.model.&lt;locals&gt;.ModelWrapper object at 0x7f4bd428a410&gt;
(ModelWrapper) self6=&lt;opto.trace.modules.model.&lt;locals&gt;.ModelWrapper object at 0x7f4bd428a410&gt;
(str) question4=Is the following sentence plausible? &quot;Marcelo got on the end of a through ball.&quot;

#Others
(str) eval3=Given the grammatical fields `question`, produce the fields `answer`: Answer: Is the following sentence plausible? &quot;Marcelo got on the end of a through ball.&quot;
(str) LLMCallable.call_llm2=Answer: Yes, the sentence &quot;Marcelo got on the end of a through ball&quot; is plausible. It is commonly used in sports commentary, especially in soccer (football), to describe a player receiving a pass that goes through the defense.

#Outputs
(str) eval4=Yes, the sentence &quot;Marcelo got on the end of a through ball&quot; is plausible. It is commonly used in sports commentary, especially in soccer (football), to describe a player receiving a pass that goes through the defense.

#Feedback
The answer is wrong. We expect the output of your answer to be &quot;yes&quot;. Please modify the prompt and relevant parts of the program to help LLM produce the right answer.

================================


Your response:

LLM response:
 {
    &quot;reasoning&quot;: &quot;The goal is to adjust the necessary variables so the final output (`eval4`) from the language model (LLM) is &#39;yes&#39;. Analyzing the processes in the code reveals that `str0`, `__code1` and `__code0` are instrumental in crafting the prompt passed into the LLM and formatting its response to extract an answer. The original format of the string template `str0` used to generate the prompt seems to influence how detailed the LLM answers. The function `create_prompt` builds the prompt using `str0`, but the prompt explicitly includes an instruction to &#39;produce the fields&#39; which might result in more elaborate answers from the LLM, not just a simple &#39;yes&#39; or &#39;no&#39;. To change this, we can tweak `str0` to request a concise response. The output is essentially derived from how the LLM responds and due to how we extract the `answer` using `__code0`, it takes everything following &#39;Answer:&#39;. Given the feedback is seeking a precise &#39;yes&#39; answer, adjustments to both the request template (`str0`) and the extraction method can be made to align outputs with expectations.&quot;,
    &quot;answer&quot;: &quot;&quot;,
    &quot;suggestion&quot;: {
        &quot;str0&quot;: &quot;Given the grammatical fields `question`, specify whether the statement is plausible in one word (yes/no):&quot;,
        &quot;__code0&quot;: &quot;def extract_answer(self, prompt_template, question, response):\n answer = response.split(&#39; &#39;)[1].strip()\n return answer&quot;
    }
}
Question: Is the following sentence plausible? &quot;Deshaun Watson was called for the goal tend in the Eastern Conference Finals.&quot;
Expected answer: no
Answer: MessageNode: (eval:6, dtype=&lt;class &#39;str&#39;&gt;, data=provide)
Output: MessageNode: (eval:6, dtype=&lt;class &#39;str&#39;&gt;, data=provide), Feedback: The answer is wrong. We expect the output of your answer to be &quot;no&quot;. Please modify the prompt and relevant parts of the program to help LLM produce the right answer., Variables:
__code:1 def create_prompt(self, prompt_template, question):
        return prompt_template.format(question)
__code:0 def extract_answer(self, prompt_template, question, response):
 answer = response.split(&#39; &#39;)[1].strip()
 return answer
str:0 Given the grammatical fields `question`, specify whether the statement is plausible in one word (yes/no):
Prompt
 
You&#39;re tasked to solve a coding/algorithm problem. You will see the instruction, the code, the documentation of each function used in the code, and the feedback about the execution result.

Specifically, a problem will be composed of the following parts:
- #Instruction: the instruction which describes the things you need to do or the question you should answer.
- #Code: the code defined in the problem.
- #Documentation: the documentation of each function used in #Code. The explanation might be incomplete and just contain high-level description. You can use the values in #Others to help infer how those functions work.
- #Variables: the input variables that you can change.
- #Constraints: the constraints or descriptions of the variables in #Variables.
- #Inputs: the values of other inputs to the code, which are not changeable.
- #Others: the intermediate values created through the code execution.
- #Outputs: the result of the code output.
- #Feedback: the feedback about the code&#39;s execution result.

In #Variables, #Inputs, #Outputs, and #Others, the format is:

&lt;data_type&gt; &lt;variable_name&gt; = &lt;value&gt;

If &lt;type&gt; is (code), it means &lt;value&gt; is the source code of a python code, which may include docstring and definitions.

Output_format: Your output should be in the following json format, satisfying the json syntax:

{{
&quot;reasoning&quot;: &lt;Your reasoning&gt;,
&quot;answer&quot;: &lt;Your answer&gt;,
&quot;suggestion&quot;: {{
    &lt;variable_1&gt;: &lt;suggested_value_1&gt;,
    &lt;variable_2&gt;: &lt;suggested_value_2&gt;,
}}
}}

In &quot;reasoning&quot;, explain the problem: 1. what the #Instruction means 2. what the #Feedback on #Output means to #Variables considering how #Variables are used in #Code and other values in #Documentation, #Inputs, #Others. 3. Reasoning about the suggested changes in #Variables (if needed) and the expected result.

If #Instruction asks for an answer, write it down in &quot;answer&quot;.

If you need to suggest a change in the values of #Variables, write down the suggested values in &quot;suggestion&quot;. Remember you can change only the values in #Variables, not others. When &lt;type&gt; of a variable is (code), you should write the new definition in the format of python code without syntax errors, and you should not change the function name or the function signature.

If no changes or answer are needed, just output TERMINATE.

Now you see problem instance:

================================

#Instruction
You need to change the &lt;value&gt; of the variables in #Variables to improve the output in accordance to #Feedback.

#Code
eval5 = eval(self=self9, prompt_template=str0, question=question6, __code=__code1)
LLMCallable.call_llm3 = LLMCallable.call_llm(self=self10, user_prompt=eval5)
eval6 = eval(self=self11, prompt_template=str0, question=question7, response=LLMCallable.call_llm3, __code=__code0)

#Documentation
[eval] This operator eval(__code, *args, **kwargs) evaluates the code block, where __code is the code (str) and *args and **kwargs are the arguments of the function. The output is the result of the evaluation, i.e., __code(*args, **kwargs).
[LLMCallable.call_llm] .

#Variables
(str) str0=Given the grammatical fields `question`, specify whether the statement is plausible in one word (yes/no):
(code) __code1:def create_prompt(self, prompt_template, question):
        return prompt_template.format(question)
(code) __code0:def extract_answer(self, prompt_template, question, response):
 answer = response.split(&#39; &#39;)[1].strip()
 return answer

#Constraints
(code) __code1: The code should start with:
def create_prompt(self, prompt_template, question):
(code) __code0: The code should start with:
def extract_answer(self, prompt_template, question, response):

#Inputs
(ModelWrapper) self11=&lt;opto.trace.modules.model.&lt;locals&gt;.ModelWrapper object at 0x7f4bd428a410&gt;
(str) question7=Is the following sentence plausible? &quot;Deshaun Watson was called for the goal tend in the Eastern Conference Finals.&quot;
(ModelWrapper) self10=&lt;opto.trace.modules.model.&lt;locals&gt;.ModelWrapper object at 0x7f4bd428a410&gt;
(ModelWrapper) self9=&lt;opto.trace.modules.model.&lt;locals&gt;.ModelWrapper object at 0x7f4bd428a410&gt;
(str) question6=Is the following sentence plausible? &quot;Deshaun Watson was called for the goal tend in the Eastern Conference Finals.&quot;

#Others
(str) eval5=Given the grammatical fields `question`, specify whether the statement is plausible in one word (yes/no):
(str) LLMCallable.call_llm3=Please provide the statement for evaluation.

#Outputs
(str) eval6=provide

#Feedback
The answer is wrong. We expect the output of your answer to be &quot;no&quot;. Please modify the prompt and relevant parts of the program to help LLM produce the right answer.

================================


Your response:

LLM response:
 {
  &quot;reasoning&quot;: &quot;The code block executes a sequence of operations involving assessment and response generation based on the question of the plausibility of a statement. The problem lies in the provided string in str0 and possibly the formulation of calls and return statements in __code0. The variable str0 is meant to construct a prompt template, and __code1 formats this to include the question. However, str0 fails to communicate clearly to the LLM that it needs to evaluate the truth of the statement, rather than asking for an explanation or any other output format. This unclear prompt might lead to LLMCallable.call_llm3 generating an unhelpful response like &#39;Please provide the statement for evaluation.&#39; Subsequently, __code0 is expected to extract the answer, but its logic needs refinement to reliably parse the response from LLM. The variable eval6 results in &#39;provide&#39; which indicates the LLM response was not correctly parsed and also shows it might not have been guided correctly by the prompt to give a yes/no answer. To address the issue, we need to reformulate the prompt in str0 and adjust the response parsing logic in __code0 to ensure a correct and clear extraction of &#39;yes&#39; or &#39;no&#39;.&quot;,
  &quot;suggestion&quot;: {
    &quot;str0&quot;: &quot;Is the statement \&quot;{question}\&quot; plausible? Answer &#39;yes&#39; or &#39;no&#39;.&quot;,
    &quot;__code0&quot;: &quot;def extract_answer(self, prompt_template, question, response):\n answer = response.strip().lower()\n return answer&quot;
  }
}
Question: Is the following sentence plausible? &quot;Mookie Betts skated behind the net.&quot;
Expected answer: no
Answer: MessageNode: (exception_eval:1, dtype=&lt;class &#39;str&#39;&gt;, data=(KeyError) &#39;question&#39;)
Output: MessageNode: (exception_eval:1, dtype=&lt;class &#39;str&#39;&gt;, data=(KeyError) &#39;question&#39;), Feedback: (KeyError) &#39;question&#39;, Variables:
__code:1 def create_prompt(self, prompt_template, question):
        return prompt_template.format(question)
__code:0 def extract_answer(self, prompt_template, question, response):
 answer = response.strip().lower()
 return answer
str:0 Is the statement &quot;{question}&quot; plausible? Answer &#39;yes&#39; or &#39;no&#39;.
Prompt
 
You&#39;re tasked to solve a coding/algorithm problem. You will see the instruction, the code, the documentation of each function used in the code, and the feedback about the execution result.

Specifically, a problem will be composed of the following parts:
- #Instruction: the instruction which describes the things you need to do or the question you should answer.
- #Code: the code defined in the problem.
- #Documentation: the documentation of each function used in #Code. The explanation might be incomplete and just contain high-level description. You can use the values in #Others to help infer how those functions work.
- #Variables: the input variables that you can change.
- #Constraints: the constraints or descriptions of the variables in #Variables.
- #Inputs: the values of other inputs to the code, which are not changeable.
- #Others: the intermediate values created through the code execution.
- #Outputs: the result of the code output.
- #Feedback: the feedback about the code&#39;s execution result.

In #Variables, #Inputs, #Outputs, and #Others, the format is:

&lt;data_type&gt; &lt;variable_name&gt; = &lt;value&gt;

If &lt;type&gt; is (code), it means &lt;value&gt; is the source code of a python code, which may include docstring and definitions.

Output_format: Your output should be in the following json format, satisfying the json syntax:

{{
&quot;reasoning&quot;: &lt;Your reasoning&gt;,
&quot;answer&quot;: &lt;Your answer&gt;,
&quot;suggestion&quot;: {{
    &lt;variable_1&gt;: &lt;suggested_value_1&gt;,
    &lt;variable_2&gt;: &lt;suggested_value_2&gt;,
}}
}}

In &quot;reasoning&quot;, explain the problem: 1. what the #Instruction means 2. what the #Feedback on #Output means to #Variables considering how #Variables are used in #Code and other values in #Documentation, #Inputs, #Others. 3. Reasoning about the suggested changes in #Variables (if needed) and the expected result.

If #Instruction asks for an answer, write it down in &quot;answer&quot;.

If you need to suggest a change in the values of #Variables, write down the suggested values in &quot;suggestion&quot;. Remember you can change only the values in #Variables, not others. When &lt;type&gt; of a variable is (code), you should write the new definition in the format of python code without syntax errors, and you should not change the function name or the function signature.

If no changes or answer are needed, just output TERMINATE.

Now you see problem instance:

================================

#Instruction
You need to change the &lt;value&gt; of the variables in #Variables to improve the output in accordance to #Feedback.

#Code
exception_eval1 = eval(self=self12, prompt_template=str0, question=question8, __code=__code1)

#Documentation
[exception] The operator eval raises an exception.

#Variables
(str) str0=Is the statement &quot;{question}&quot; plausible? Answer &#39;yes&#39; or &#39;no&#39;.
(code) __code1:def create_prompt(self, prompt_template, question):
        return prompt_template.format(question)

#Constraints
(code) __code1: The code should start with:
def create_prompt(self, prompt_template, question):

#Inputs
(ModelWrapper) self12=&lt;opto.trace.modules.model.&lt;locals&gt;.ModelWrapper object at 0x7f4bd428a410&gt;
(str) question8=Is the following sentence plausible? &quot;Mookie Betts skated behind the net.&quot;

#Others


#Outputs
(str) exception_eval1=(KeyError) &#39;question&#39;

#Feedback
(KeyError) &#39;question&#39;

================================


Your response:

LLM response:
 {
  &quot;reasoning&quot;: &quot;The operation fails because it is trying to use the Python str.format method in the __code1 function, and is looking for a key named &#39;question&#39; in the format string. However, in the original format string &#39;str0&#39;, this key is represented as {question} inside double quotes, which Python cannot recognize as the names of the placeholders for the format method. As a result, the KeyError means that the template string &#39;str0&#39; does not match the expected format string requirements where placeholder names are used directly without additional quotes or alterations.&quot;,
  &quot;answer&quot;: &quot;&quot;,
  &quot;suggestion&quot;: {
    &quot;str0&quot;: &quot;Is the statement {question} plausible? Answer &#39;yes&#39; or &#39;no&#39;.&quot;
  }
}

Testing on new examples:
Accuracy:  0.0
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Generating train split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [00:00&lt;00:00, 40783.17 examples/s]
</pre></div>
</div>
</div>
</div>
<p>Now, you can run each cell in this notebook step by step to walk through the process of setting up and optimizing prompts. Happy optimizing!</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./examples/nlp"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../game/negotiation_arena.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Multi-Agent: Negotiation Arena</p>
      </div>
    </a>
    <a class="right-next"
       href="../robotics/metaworld.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Meta-World</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setup">Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#define-the-evaluation-function">Define the Evaluation Function</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#helper-function">Helper Function</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#define-a-traced-class">Define a Traced Class</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#define-the-optimizer">Define the optimizer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#putting-it-all-together">Putting it all together</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Ching-An Cheng, Allen Nie, Adith Swaminathan
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      ¬© Copyright 2024 Trace Team.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <a href='mailto:chinganc@microsoft.com'>Contact Us</a> | <a href='http://go.microsoft.com/fwlink/?LinkId=521839'>Privacy &amp; Cookies</a> | <a href='https://go.microsoft.com/fwlink/?linkid=2259814'>Consumer Health Privacy</a> | <a href='https://go.microsoft.com/fwlink/?LinkID=206977'>Terms Of Use</a> | <a href='https://www.microsoft.com/trademarks'>Trademarks</a>
</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>